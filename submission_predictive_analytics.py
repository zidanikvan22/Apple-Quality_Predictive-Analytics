# -*- coding: utf-8 -*-
"""Submission_Predictive-Analytics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uWL3S6yH5e-0nah0W5TgFrkqh3REibiT

# **Proyek Pertama Machine Learning Terapan - Predictive Analytics**

**Nama: Zidan Muhammad Ikvan** |
**Cohort ID: MC404D5Y0059** |
**Email: zidanikvan@gmail.com**

## **1. Data Understanding**

Dataset [ini](https://www.kaggle.com/datasets/nelgiriyewithana/apple-quality) disediakan dengan murah hati oleh sebuah perusahaan pertanian Amerika. Dataset ini berisi informasi tentang berbagai atribut dari sekumpulan buah apel, yang memberikan wawasan tentang karakteristiknya. Dataset ini mencakup detail seperti  fruit ID, size, weight, sweetness, crunchiness, juiciness, ripeness, acidity, and quality.

"Pada bagian ini, kita akan melakukan eksplorasi data untuk memahami struktur dan informasi yang terkandung dalam dataset buah apel. Dataset ini memiliki 4.001 sampel buah apel dengan berbagai karakteristik dan kualitas. Karakteristik yang dimaksud di sini meliputi fitur numerik seperti Size, Weight, Sweetness, Crunchiness, Juiciness, Ripeness, dan Acidity, serta fitur non-numerik seperti Quality. Kedelapan fitur ini akan digunakan untuk menemukan pola pada data, sedangkan Quality merupakan fitur target yang menunjukkan kelas kualitas buah apel. Kualitas apel dalam dataset ini terbagi menjadi dua kategori: good (baik) dan bad (buruk)."

1. A_id: Pengenal unik untuk setiap buah
2. Size: Ukuran buah
3. Weight: Berat buah
4. Sweetness: Tingkat kemanisan buah
5. Crunchinesss: Tekstur yang menunjukkan kerenyahan buah
6. Juiciness: Tingkat kesegaran buah
7. Ripeness: Tahap kematangan buah
8. Acidity: Tingkat keasaman buah
9. Quality: Kualitas buah secara keseluruhan (Target)

## **2. Import Libray/Package**

pandas & numpy → Manipulasi data.

matplotlib & seaborn → Visualisasi data.

sklearn → Preprocessing data, pembagian dataset, pelatihan model (Random Forest), dan evaluasi kinerja.
"""

# Untuk manipulasi data
import pandas as pd
import numpy as np

# Untuk visualisasi data
import matplotlib.pyplot as plt
import seaborn as sns

# Untuk preprocessing Preprocessing data, pembagian dataset, pelatihan model (Random Forest), dan evaluasi kinerja.
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV

"""## **3. Load Data**

*  Upload file dataset ke Google Colab.
*  Membaca dataset menggunakan pandas.
*  Menampilkan informasi awal DataFrame untuk memastikan dataset sudah benar terbaca.
"""

# Load dataset
df = pd.read_csv('apple_quality.csv')

# Menampilkan 10 data teratas
print("Preview Data:")
display(df.head(10))

"""## **4. Exploratory Data Analysis**

EDA (Exploratory Data Analysis) bertujuan untuk memahami karakteristik data sebelum digunakan untuk model machine learning. Proses ini membantu kita dalam beberapa aspek penting, seperti:

* Mendeteksi outlier yang dapat memengaruhi performa model

* Mengidentifikasi missing values/duplikat yang perlu diimputasi atau dihapus

* Menganalisis distribusi data untuk memahami penyebaran dan skewness tiap fitur

* Menemukan korelasi antar fitur yang mungkin berpengaruh pada prediksi

* Memahami karakteristik label target, termasuk class imbalance pada kasus klasifikasi
"""

# Info umum dataset
print("\nInfo Dataset:")
print(df.info())

# Cek jumlah data hilang (null)
print("\nJumlah Missing Value per Kolom:")
print(df.isnull().sum())

# Cek duplikasi data
print("\nJumlah data duplikat:")
print(df.duplicated().sum())

# Menghapus missing values
df = df.dropna()

# Statistik deskriptif untuk fitur numerik
df.describe()

# Plot distribusi kelas target
sns.countplot(x='Quality', data=df)
plt.title('Distribusi Kelas Quality (good vs bad)')
plt.show()

# Rasio persentase
print(df['Quality'].value_counts(normalize=True) * 100)

numerical_cols = ['Size', 'Weight', 'Sweetness', 'Crunchiness', 'Juiciness', 'Ripeness']

# Plot histogram untuk masing-masing fitur
df[numerical_cols].hist(figsize=(12, 10), bins=30, color='skyblue', edgecolor='black')
plt.tight_layout()
plt.show()

# Hitung korelasi
correlation_matrix = df[numerical_cols].corr()

# Visualisasi dengan heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Korelasi Antar Fitur Numerik')
plt.show()

# Boxplot untuk masing-masing fitur numerik
plt.figure(figsize=(12, 10))
for i, col in enumerate(numerical_cols, 1):
    plt.subplot(3, 2, i)
    sns.boxplot(x=df[col], color='lightgreen')
    plt.title(f'Outlier pada {col}')
plt.tight_layout()
plt.show()

print("Kolom Object:")
print(df.select_dtypes(include='object').nunique())
print("\nSample Value:")
print(df.select_dtypes(include='object').head())

"""## **5. Data Preparation**

Data preparation merupakan tahap penting dalam mempersiapkan data sebelum pemodelan machine learning. Proses ini bertujuan untuk memastikan data dalam format yang sesuai dan optimal untuk diproses oleh algoritma.

Tahapan utama yang dilakukan meliputi:

* Konversi tipe data untuk memastikan konsistensi format

* Pemisahan fitur (X) dan target (y) untuk pembelajaran model

* Pembagian data training dan testing untuk evaluasi yang valid

* Normalisasi/scaling untuk menyamakan skala fitur

* Pengecekan final shape sebelum pemodelan

Dengan melakukan persiapan data secara menyeluruh, kita dapat meningkatkan kualitas model dan mencegah masalah yang mungkin timbul selama proses machine learning.
"""

# Ubah 'Acidity' jadi float
df['Acidity'] = df['Acidity'].astype(float)

# Ubah 'Quality' jadi 0/1 | 0 = bad, 1 = good
df['Quality'] = df['Quality'].map({'bad': 0, 'good': 1})

# Pemisahan Fitur dan Target
X = df.drop(columns=['A_id', 'Quality'])
y = df['Quality']

# Pembagian Data: Train-Test Split 80:20
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y)

# Standarisasi Fitur Numerik (Scaling)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Mengecek Final Shape dan Siap Modeling
print("X_train:", X_train_scaled.shape)
print("X_test:", X_test_scaled.shape)
print("y_train:", y_train.shape)
print("y_test:", y_test.shape)

"""## **6. Modelling**

Mengimplementasikan classifier Random Forest menggunakan data training yang telah dipersiapkan. Metode ensemble ini membangun banyak decision tree untuk meningkatkan performa prediksi dan mengurangi overfitting.

Langkah utama:

* Inisialisasi model dengan random_state=42 untuk hasil yang reproducible

* Melatih model menggunakan fitur yang telah discale (X_train_scaled) dan label (y_train)

Parameter default Random Forest memberikan baseline yang kuat, yang nantinya bisa dioptimasi melalui hyperparameter tuning jika diperlukan.
"""

# Random Forest
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train_scaled, y_train)

"""## **7. Evaluasi**

* Memeriksa apakah model mengalami overfitting (akurasi train jauh lebih tinggi dari test)

* Mengukur performa model secara objektif menggunakan metrik standar

* Memastikan model dapat bekerja dengan baik pada data yang belum pernah dilihat sebelumnya
* Menampilkan classification report yang berisi: Precision, Recall, F1-score, Support
"""

# Prediksi pada data latih
rf_train_pred = rf_model.predict(X_train_scaled)

# Evaluasi Random Forest (Train)
print("=== Random Forest (Train Data) ===")
print(confusion_matrix(y_train, rf_train_pred))
print(classification_report(y_train, rf_train_pred))

# Prediksi pada data test
rf_pred = rf_model.predict(X_test_scaled)

# Evaluasi Random Forest
print("=== Random Forest (test) ===")
print(confusion_matrix(y_test, rf_pred))
print(classification_report(y_test, rf_pred))

"""## **8. Model Tuned & Evaluasi**

1. Tuning (GridSearchCV)

    - Mencari kombinasi parameter terbaik untuk meningkatkan performa model

    - Mencegah overfitting/underfitting

2. Evaluasi

    - Memvalidasi kemampuan model pada data training dan testing

    - Memastikan model memiliki generalisasi yang baik
"""

# Inisialisasi model dasar
rf_model = RandomForestClassifier(random_state=42)

# Daftar parameter yang akan diuji
param_grid = {
    'n_estimators': [150, 200],
    'max_depth': [15, 20],
    'min_samples_split': [5, 10],
    'min_samples_leaf': [3, 5],
    'max_features': ['sqrt', 'log2']
}

# GridSearch dengan 5-fold cross-validation
grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)

# Fit model ke data training
grid_search.fit(X_train_scaled, y_train)

# Tampilkan parameter terbaik
print("Best Parameters:", grid_search.best_params_)

# Random Forest dengan parameter terbaik dari GridSearchCV
rf_model_tuned = RandomForestClassifier(
    n_estimators=150,
    max_depth=20,
    min_samples_split=5,
    min_samples_leaf=3,
    max_features='sqrt',
    random_state=42
)

# Latih model
rf_model_tuned.fit(X_train_scaled, y_train)

# Evaluasi di data latih & data uji

print("=== Random Forest (Train Data, Tuned) ===")
y_train_pred = rf_model_tuned.predict(X_train_scaled)
print(confusion_matrix(y_train, y_train_pred))
print(classification_report(y_train, y_train_pred))

print("=== Random Forest (Test Data, Tuned) ===")
y_test_pred = rf_model_tuned.predict(X_test_scaled)
print(confusion_matrix(y_test, y_test_pred))
print(classification_report(y_test, y_test_pred))

"""## **9. Inference**

Tujuan Inference:

- Menguji kemampuan model pada data baru yang belum pernah diproses sebelumnya

- Memverifikasi performa model dalam kondisi nyata

- Memberikan insight tentang keputusan model melalui probabilitas prediksi

1. Inference dengan Data Dummy

  * Membuat data contoh baru yang mensimulasikan input nyata

  * Melakukan prediksi kualitas apel (Good/Bad) beserta probabilitasnya

  * Menampilkan hasil prediksi bersama dengan data input
"""

# Data dummy untuk inference
data_inference = pd.DataFrame({
    'Size': [0.2, -0.8, 1.1, -0.5, 0.0],
    'Weight': [-0.1, 0.6, -1.2, 0.9, -0.3],
    'Sweetness': [2.0, 1.3, -0.8, 2.8, -1.1],
    'Crunchiness': [0.6, -1.0, 1.5, 0.8, -0.2],
    'Juiciness': [1.2, -0.5, 2.4, 0.7, -1.4],
    'Ripeness': [0.1, 1.0, 0.2, 1.8, -0.6],
    'Acidity': [-0.4, 0.9, -1.0, 0.1, -2.0]
})

# Inference: Prediksi kualitas apel dengan model Random Forest yang sudah dituning
prediksi_kualitas = rf_model_tuned.predict(data_inference)
prediksi_probabilitas = rf_model_tuned.predict_proba(data_inference)

# Menampilkan hasil
hasil = data_inference.copy()
hasil['Predicted Quality'] = prediksi_kualitas
hasil['Probability (Bad)'] = prediksi_probabilitas[:, 0]
hasil['Probability (Good)'] = prediksi_probabilitas[:, 1]

print(hasil)

"""2. Inference dengan Data Test

    * Mengambil sample data dari test set yang belum pernah dilihat model

    * Membandingkan hasil prediksi dengan label sebenarnya (actual)

    * Menampilkan probabilitas prediksi untuk setiap kelas
"""

# Ambil 5 data dari test set untuk inference dengan label asli
X_infer = X_test.iloc[:5]
y_actual = y_test.iloc[:5]

# Prediksi dengan model Random Forest yang sudah dituning
y_pred = rf_model_tuned.predict(X_infer)
y_proba = rf_model_tuned.predict_proba(X_infer)

# Gabungkan hasil prediksi dan label asli
hasil_inferensi = X_infer.copy()
hasil_inferensi['Actual'] = y_actual.values
hasil_inferensi['Predicted'] = y_pred
hasil_inferensi['Probability (Bad)'] = y_proba[:, 0]
hasil_inferensi['Probability (Good)'] = y_proba[:, 1]

# Tampilkan
print(hasil_inferensi)